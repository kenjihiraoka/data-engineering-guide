Data Engineering Guide
==========================

This is a repo with tools used in data engineering


# File Format (serialization)
* [Apache Avro](https://avro.apache.org) Apache Avro is row-oriented serialization that use JSON for defining data types and protocols.
* [Apache Parquet](https://parquet.apache.org) Apache Parquet is an open-source column-oriented serialization, is's specialized in efficiently storing and processing nested data types.
* [Apache ORC](https://orc.apache.org/) Apache ORC is a column-oriented serialization highly optimized for reading and writing.

# Pipeline Orchestration
* [Apache Airflow](https://github.com/apache/airflow) Apache Airflow is an open-source workflow management plataform, it schedule workflows and monitor them via your own UI.
* [Azkaban](https://azkaban.github.io/) Azkaban is a batch workflow job scheduler.
* [Kedro](https://github.com/quantumblacklabs/kedro) Kedro is a development workflow framework that implements software engineering best-practice for data pipelines.
* [Luigi](https://github.com/spotify/luigi) Luigi helps you to build batch jobs pipelines and monitor them all.
